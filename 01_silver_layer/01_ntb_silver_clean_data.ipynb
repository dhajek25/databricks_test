{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3844612-e26c-44b8-aaee-13f00e9e948b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78324a1f-4c60-4ca0-8d18-349fadfe646b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json, to_timestamp, year\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, StructField, TimestampType, LongType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b2a4fc-ecd2-4af4-89c1-d07f5eac2b8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0cccfd9-91a9-48b9-a794-dc2f19e774cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read Bronze Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b18eba79-14d3-4232-95ee-d5c243dbca01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the bronze layer tables\n",
    "event_df_bronze = spark.read.table(\"workspace.bronze_layer.bronze_event\")\n",
    "\n",
    "item_df_bronze = spark.read.table(\"workspace.bronze_layer.bronze_item\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8936af32-249d-4c1f-8b74-596f02d04405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "288db708-26da-49fc-a4f8-1af365a2abb0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Unify attribute naming for silver layer"
    }
   },
   "outputs": [],
   "source": [
    "# Define unified column names for item_df_bronze\n",
    "item_rename_map = {\n",
    "    \"adjective\": \"item_adjective\",\n",
    "    \"category\": \"item_category\",\n",
    "    \"created_at\": \"item_created_at\",\n",
    "    \"id\": \"item_id\",\n",
    "    \"modifier\": \"item_modifier\",\n",
    "    \"name\": \"item_name\",\n",
    "    \"price\": \"item_price\",\n",
    "    \"tc_ingestion_timestamp\": \"tc_ingestion_timestamp\",\n",
    "    \"tc_source_file\": \"tc_source_file\",\n",
    "    \"tc_bronze_id\": \"tc_bronze_id\"\n",
    "}\n",
    "# Apply column renaming to item_df_bronze \n",
    "item_df_silver = item_df_bronze.select([col(c).alias(item_rename_map.get(c, c)) for c in item_df_bronze.columns])\n",
    "\n",
    "# Define unified column names for event_df_bronze\n",
    "# Flatten event.payload if it's a JSON string\n",
    "\n",
    "event_rename_map = {\n",
    "    \"event_id\": \"event_id\",\n",
    "    \"event_time\": \"event_time\",\n",
    "    \"user_id\": \"event_user_id\",\n",
    "    \"event_payload\": \"event_payload\",\n",
    "    \"tc_ingestion_timestamp\": \"tc_ingestion_timestamp\",\n",
    "    \"tc_source_file\": \"tc_source_file\",\n",
    "    \"tc_bronze_id\": \"tc_bronze_id\"\n",
    "}\n",
    "\n",
    "# Rename columns with dots to underscores\n",
    "# event_df_bronze = event_df_bronze.toDF(*[c.replace('.', '_') for c in event_df_bronze.columns])\n",
    "\n",
    "# Apply column renaming to event_df_bronze\n",
    "event_df_silver = event_df_bronze.select([col(c).alias(event_rename_map.get(c, c)) for c in event_rename_map.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6517d8a4-da55-409a-a6b0-0d64788777d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for event_payload\n",
    "payload_schema = StructType([\n",
    "    StructField(\"event_name\", StringType(), True),\n",
    "    StructField(\"platform\", StringType(), True),\n",
    "    StructField(\"parameter_name\", StringType(), True),\n",
    "    StructField(\"parameter_value\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Cast columns in event_df_silver\n",
    "event_df_casted = event_df_silver \\\n",
    "    .withColumn(\"event_id\", col(\"event_id\").cast(StringType())) \\\n",
    "    .withColumn(\"event_time\", to_timestamp(col(\"event_time\"))) \\\n",
    "    .withColumn(\"event_user_id\", col(\"event_user_id\").cast(DoubleType())) \\\n",
    "    .withColumn(\"event_payload\", from_json(col(\"event_payload\"), payload_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85596d5f-b642-449d-a6c4-df07fabe13c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast columns in event_df_silver\n",
    "event_df_casted = event_df_silver \\\n",
    "    .withColumn(\"event_id\", col(\"event_id\").cast(StringType())) \\\n",
    "    .withColumn(\"event_time\", to_timestamp(col(\"event_time\"))) \\\n",
    "    .withColumn(\"event_user_id\", col(\"event_user_id\").cast(\"double\").cast(\"bigint\")) \\\n",
    "    .withColumn(\"event_payload\", from_json(col(\"event_payload\"), payload_schema))\n",
    "\n",
    "# Cast columns in item_df_silver\n",
    "item_df_casted = item_df_silver \\\n",
    "    .withColumn(\"item_id\", col(\"item_id\").cast(\"double\").cast(\"bigint\")) \\\n",
    "    .withColumn(\"item_created_at\", to_timestamp(col(\"item_created_at\"))) \\\n",
    "    .withColumn(\"item_price\", col(\"item_price\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7f4389c-7d28-4c9f-ab78-b3825569d834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare column lists for flattening event_payload and selecting unified columns for the silver layer\n",
    "technical_cols = [\"tc_ingestion_timestamp\", \"tc_source_file\", \"tc_bronze_id\"]\n",
    "main_cols = [c for c in event_df_casted.columns if c not in technical_cols + [\"event_payload\"]]\n",
    "unpacked_cols = [\"event_name\", \"event_platform\", \"event_parameter_name\", \"event_parameter_value\"]\n",
    "\n",
    "# Unpack event_payload struct into separate columns for event_df_casted using payload_schema\n",
    "# Description: This step flattens the event_payload struct into individual columns and selects unified columns for the silver layer.\n",
    "event_df_final = event_df_casted \\\n",
    "    .withColumn(\"event_name\", col(\"event_payload.event_name\")) \\\n",
    "    .withColumn(\"event_platform\", col(\"event_payload.platform\")) \\\n",
    "    .withColumn(\"event_parameter_name\", col(\"event_payload.parameter_name\")) \\\n",
    "    .withColumn(\"event_parameter_value\", col(\"event_payload.parameter_value\")) \\\n",
    "    .drop(\"event_payload\") \\\n",
    "    .select(*(main_cols + unpacked_cols + technical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "657d4c26-4cae-4cb8-9b32-0013c96d018d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41502ef3-4df3-43fc-82a7-2a895f98ce65",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save DataFrames to silver_layer"
    }
   },
   "outputs": [],
   "source": [
    "# Add year column for partitioning\n",
    "event_df_final_with_year = event_df_final.withColumn(\"event_year\", year(col(\"event_time\")))\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver_layer\")\n",
    "\n",
    "# Save event_df_final partitioned by year\n",
    "(event_df_final_with_year\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"event_year\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"workspace.silver_layer.silver_event\")\n",
    ")\n",
    "\n",
    "# Save item_df_casted without partitioning\n",
    "(item_df_casted\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"workspace.silver_layer.silver_item\")\n",
    ")\n",
    "\n",
    "print(\"Saved event_df_final as workspace.silver_layer.silver_event partitioned by year.\")\n",
    "print(\"Saved item_df_casted as workspace.silver_layer.silver_item.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ntb_silver_clean_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
